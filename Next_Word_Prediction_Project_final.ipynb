{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjhXhkffq8F4qScRewl5VZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna4003/Next-Word-Prediction-Project/blob/main/Next_Word_Prediction_Project_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpSJwXniUGhd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faqs = \"\"\"About the Program\n",
        "What is the course fee for Data Science Mentorship Program\n",
        "The course follows a monthly subscription model where you have to make monthly payments of RS 800\n",
        "what is the total duration of the course?\n",
        "what is the syllabus of mentorship program?\n",
        "we will be covering the following modules:\n",
        "Python fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning will not be a part of this program's curriculum\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes, all our sessions are recorded, so even if you miss a session you can go back and watch the recording\n",
        "What is the time duration of all the sessions?\n",
        "Roughly, all the sessions last 2 hours?\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "h0kwCmouUSkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the tokenizer and fit on the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "SdAYJ4riUT_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieving the Word Index:\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VNTOR5HXxt0",
        "outputId": "36fc1838-1d5b-48e9-d519-c5b3f42c29d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'a': 3,\n",
              " 'what': 4,\n",
              " 'program': 5,\n",
              " 'is': 6,\n",
              " 'for': 7,\n",
              " 'data': 8,\n",
              " 'will': 9,\n",
              " 'course': 10,\n",
              " 'science': 11,\n",
              " 'you': 12,\n",
              " 'be': 13,\n",
              " 'learning': 14,\n",
              " 'and': 15,\n",
              " 'session': 16,\n",
              " 'all': 17,\n",
              " 'sessions': 18,\n",
              " 'mentorship': 19,\n",
              " 'monthly': 20,\n",
              " 'duration': 21,\n",
              " 'python': 22,\n",
              " 'ml': 23,\n",
              " 'deep': 24,\n",
              " 'nlp': 25,\n",
              " 'part': 26,\n",
              " 'this': 27,\n",
              " 'if': 28,\n",
              " 'i': 29,\n",
              " 'miss': 30,\n",
              " 'recording': 31,\n",
              " 'about': 32,\n",
              " 'fee': 33,\n",
              " 'follows': 34,\n",
              " 'subscription': 35,\n",
              " 'model': 36,\n",
              " 'where': 37,\n",
              " 'have': 38,\n",
              " 'to': 39,\n",
              " 'make': 40,\n",
              " 'payments': 41,\n",
              " 'rs': 42,\n",
              " '800': 43,\n",
              " 'total': 44,\n",
              " 'syllabus': 45,\n",
              " 'we': 46,\n",
              " 'covering': 47,\n",
              " 'following': 48,\n",
              " 'modules': 49,\n",
              " 'fundamentals': 50,\n",
              " 'libraries': 51,\n",
              " 'analysis': 52,\n",
              " 'sql': 53,\n",
              " 'maths': 54,\n",
              " 'machine': 55,\n",
              " 'algorithms': 56,\n",
              " 'practical': 57,\n",
              " 'mlops': 58,\n",
              " 'case': 59,\n",
              " 'studies': 60,\n",
              " 'no': 61,\n",
              " 'not': 62,\n",
              " \"program's\": 63,\n",
              " 'curriculum': 64,\n",
              " 'live': 65,\n",
              " 'get': 66,\n",
              " 'yes': 67,\n",
              " 'our': 68,\n",
              " 'are': 69,\n",
              " 'recorded': 70,\n",
              " 'so': 71,\n",
              " 'even': 72,\n",
              " 'can': 73,\n",
              " 'go': 74,\n",
              " 'back': 75,\n",
              " 'watch': 76,\n",
              " 'time': 77,\n",
              " 'roughly': 78,\n",
              " 'last': 79,\n",
              " '2': 80,\n",
              " 'hours': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in faqs.split('\\n'): # Breakdown the faqs dataset into sentence by sentence on the basis of line change\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0]) # 2D list->1D list using [0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL_FpArlYKYr",
        "outputId": "061c1495-b44e-4108-f50c-084f72dfaee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 1, 5]\n",
            "[4, 6, 1, 10, 33, 7, 8, 11, 19, 5]\n",
            "[1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39, 40, 20, 41, 2, 42, 43]\n",
            "[4, 6, 1, 44, 21, 2, 1, 10]\n",
            "[4, 6, 1, 45, 2, 19, 5]\n",
            "[46, 9, 13, 47, 1, 48, 49]\n",
            "[22, 50]\n",
            "[22, 51, 7, 8, 11]\n",
            "[8, 52]\n",
            "[53, 7, 8, 11]\n",
            "[54, 7, 55, 14]\n",
            "[23, 56]\n",
            "[57, 23]\n",
            "[58]\n",
            "[59, 60]\n",
            "[9, 24, 14, 15, 25, 13, 3, 26, 2, 27, 5]\n",
            "[61, 25, 15, 24, 14, 9, 62, 13, 3, 26, 2, 27, 63, 64]\n",
            "[4, 28, 29, 30, 3, 65, 16, 9, 29, 66, 3, 31, 2, 1, 16]\n",
            "[67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16, 12, 73, 74, 75, 15, 76, 1, 31]\n",
            "[4, 6, 1, 77, 21, 2, 17, 1, 18]\n",
            "[78, 17, 1, 18, 79, 80, 81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1  #Including the reserved 0 index\n",
        "print(f'Vocabulary Size: {vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPc2eIzeUYQO",
        "outputId": "0b13cc68-fe60-4b39-feaa-d6923096a4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " input_sequences=[]\n",
        " for sentence in faqs.split('\\n'):\n",
        "\n",
        "  tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "Gb1VAetYUhrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences#(2-d list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxB16Bn7UmXN",
        "outputId": "ed30828c-2aea-47cf-da9f-13f53fa8eb30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32, 1],\n",
              " [32, 1, 5],\n",
              " [4, 6],\n",
              " [4, 6, 1],\n",
              " [4, 6, 1, 10],\n",
              " [4, 6, 1, 10, 33],\n",
              " [4, 6, 1, 10, 33, 7],\n",
              " [4, 6, 1, 10, 33, 7, 8],\n",
              " [4, 6, 1, 10, 33, 7, 8, 11],\n",
              " [4, 6, 1, 10, 33, 7, 8, 11, 19],\n",
              " [4, 6, 1, 10, 33, 7, 8, 11, 19, 5],\n",
              " [1, 10],\n",
              " [1, 10, 34],\n",
              " [1, 10, 34, 3],\n",
              " [1, 10, 34, 3, 20],\n",
              " [1, 10, 34, 3, 20, 35],\n",
              " [1, 10, 34, 3, 20, 35, 36],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39, 40],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39, 40, 20],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39, 40, 20, 41],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39, 40, 20, 41, 2],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39, 40, 20, 41, 2, 42],\n",
              " [1, 10, 34, 3, 20, 35, 36, 37, 12, 38, 39, 40, 20, 41, 2, 42, 43],\n",
              " [4, 6],\n",
              " [4, 6, 1],\n",
              " [4, 6, 1, 44],\n",
              " [4, 6, 1, 44, 21],\n",
              " [4, 6, 1, 44, 21, 2],\n",
              " [4, 6, 1, 44, 21, 2, 1],\n",
              " [4, 6, 1, 44, 21, 2, 1, 10],\n",
              " [4, 6],\n",
              " [4, 6, 1],\n",
              " [4, 6, 1, 45],\n",
              " [4, 6, 1, 45, 2],\n",
              " [4, 6, 1, 45, 2, 19],\n",
              " [4, 6, 1, 45, 2, 19, 5],\n",
              " [46, 9],\n",
              " [46, 9, 13],\n",
              " [46, 9, 13, 47],\n",
              " [46, 9, 13, 47, 1],\n",
              " [46, 9, 13, 47, 1, 48],\n",
              " [46, 9, 13, 47, 1, 48, 49],\n",
              " [22, 50],\n",
              " [22, 51],\n",
              " [22, 51, 7],\n",
              " [22, 51, 7, 8],\n",
              " [22, 51, 7, 8, 11],\n",
              " [8, 52],\n",
              " [53, 7],\n",
              " [53, 7, 8],\n",
              " [53, 7, 8, 11],\n",
              " [54, 7],\n",
              " [54, 7, 55],\n",
              " [54, 7, 55, 14],\n",
              " [23, 56],\n",
              " [57, 23],\n",
              " [59, 60],\n",
              " [9, 24],\n",
              " [9, 24, 14],\n",
              " [9, 24, 14, 15],\n",
              " [9, 24, 14, 15, 25],\n",
              " [9, 24, 14, 15, 25, 13],\n",
              " [9, 24, 14, 15, 25, 13, 3],\n",
              " [9, 24, 14, 15, 25, 13, 3, 26],\n",
              " [9, 24, 14, 15, 25, 13, 3, 26, 2],\n",
              " [9, 24, 14, 15, 25, 13, 3, 26, 2, 27],\n",
              " [9, 24, 14, 15, 25, 13, 3, 26, 2, 27, 5],\n",
              " [61, 25],\n",
              " [61, 25, 15],\n",
              " [61, 25, 15, 24],\n",
              " [61, 25, 15, 24, 14],\n",
              " [61, 25, 15, 24, 14, 9],\n",
              " [61, 25, 15, 24, 14, 9, 62],\n",
              " [61, 25, 15, 24, 14, 9, 62, 13],\n",
              " [61, 25, 15, 24, 14, 9, 62, 13, 3],\n",
              " [61, 25, 15, 24, 14, 9, 62, 13, 3, 26],\n",
              " [61, 25, 15, 24, 14, 9, 62, 13, 3, 26, 2],\n",
              " [61, 25, 15, 24, 14, 9, 62, 13, 3, 26, 2, 27],\n",
              " [61, 25, 15, 24, 14, 9, 62, 13, 3, 26, 2, 27, 63],\n",
              " [61, 25, 15, 24, 14, 9, 62, 13, 3, 26, 2, 27, 63, 64],\n",
              " [4, 28],\n",
              " [4, 28, 29],\n",
              " [4, 28, 29, 30],\n",
              " [4, 28, 29, 30, 3],\n",
              " [4, 28, 29, 30, 3, 65],\n",
              " [4, 28, 29, 30, 3, 65, 16],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9, 29],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9, 29, 66],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9, 29, 66, 3],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9, 29, 66, 3, 31],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9, 29, 66, 3, 31, 2],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9, 29, 66, 3, 31, 2, 1],\n",
              " [4, 28, 29, 30, 3, 65, 16, 9, 29, 66, 3, 31, 2, 1, 16],\n",
              " [67, 17],\n",
              " [67, 17, 68],\n",
              " [67, 17, 68, 18],\n",
              " [67, 17, 68, 18, 69],\n",
              " [67, 17, 68, 18, 69, 70],\n",
              " [67, 17, 68, 18, 69, 70, 71],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16, 12],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16, 12, 73],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16, 12, 73, 74],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16, 12, 73, 74, 75],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16, 12, 73, 74, 75, 15],\n",
              " [67, 17, 68, 18, 69, 70, 71, 72, 28, 12, 30, 3, 16, 12, 73, 74, 75, 15, 76],\n",
              " [67,\n",
              "  17,\n",
              "  68,\n",
              "  18,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  28,\n",
              "  12,\n",
              "  30,\n",
              "  3,\n",
              "  16,\n",
              "  12,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  15,\n",
              "  76,\n",
              "  1],\n",
              " [67,\n",
              "  17,\n",
              "  68,\n",
              "  18,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  28,\n",
              "  12,\n",
              "  30,\n",
              "  3,\n",
              "  16,\n",
              "  12,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  15,\n",
              "  76,\n",
              "  1,\n",
              "  31],\n",
              " [4, 6],\n",
              " [4, 6, 1],\n",
              " [4, 6, 1, 77],\n",
              " [4, 6, 1, 77, 21],\n",
              " [4, 6, 1, 77, 21, 2],\n",
              " [4, 6, 1, 77, 21, 2, 17],\n",
              " [4, 6, 1, 77, 21, 2, 17, 1],\n",
              " [4, 6, 1, 77, 21, 2, 17, 1, 18],\n",
              " [78, 17],\n",
              " [78, 17, 1],\n",
              " [78, 17, 1, 18],\n",
              " [78, 17, 1, 18, 79],\n",
              " [78, 17, 1, 18, 79, 80],\n",
              " [78, 17, 1, 18, 79, 80, 81]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "[len(x) for x in input_sequences]\n",
        "\n"
      ],
      "metadata": {
        "id": "CotBGhH1Uqkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdb13f5-f523-417f-b657-14f00745f506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequences])\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBpvQgFeF-V9",
        "outputId": "c1eca4e7-84bc-47d8-8071-37e385923f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences to the same length\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')\n",
        "print(padded_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqunauBXGRON",
        "outputId": "59d5c73e-f32d-45ec-de09-955b5b424225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0 ...  0 32  1]\n",
            " [ 0  0  0 ... 32  1  5]\n",
            " [ 0  0  0 ...  0  4  6]\n",
            " ...\n",
            " [ 0  0  0 ...  1 18 79]\n",
            " [ 0  0  0 ... 18 79 80]\n",
            " [ 0  0  0 ... 79 80 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input (X) and output (y)\n",
        "X = padded_sequences[:, :-1] # all rows and exclude last column\n",
        "y = padded_sequences[:, -1]  # all rows and include last column"
      ],
      "metadata": {
        "id": "7aNX-zvhUuWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzDm2i3YNdmC",
        "outputId": "ac976e65-2f74-4f45-f4d5-448422d656ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDGl0C3TNg_s",
        "outputId": "03ecb9b5-221c-4086-b413-18a09285b307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrcrJNvVUxz7",
        "outputId": "44c72db6-2678-4820-b553-5e918c7881e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0 ...  0  0 32]\n",
            " [ 0  0  0 ...  0 32  1]\n",
            " [ 0  0  0 ...  0  0  4]\n",
            " ...\n",
            " [ 0  0  0 ... 17  1 18]\n",
            " [ 0  0  0 ...  1 18 79]\n",
            " [ 0  0  0 ... 18 79 80]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP-xfiz2U06t",
        "outputId": "04ed95e1-813b-406b-e060-0592566fe803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  5  6  1 10 33  7  8 11 19  5 10 34  3 20 35 36 37 12 38 39 40 20 41\n",
            "  2 42 43  6  1 44 21  2  1 10  6  1 45  2 19  5  9 13 47  1 48 49 50 51\n",
            "  7  8 11 52  7  8 11  7 55 14 56 23 60 24 14 15 25 13  3 26  2 27  5 25\n",
            " 15 24 14  9 62 13  3 26  2 27 63 64 28 29 30  3 65 16  9 29 66  3 31  2\n",
            "  1 16 17 68 18 69 70 71 72 28 12 30  3 16 12 73 74 75 15 76  1 31  6  1\n",
            " 77 21  2 17  1 18 17  1 18 79 80 81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ0pJp_1LqTz",
        "outputId": "e6a00eb2-4fbd-42df-bdb3-38c526fcd9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the output to categorical\n",
        "y = to_categorical(y, num_classes=82)# Here no of classes=len(tokenizer.word_index)+1=81+1=82"
      ],
      "metadata": {
        "id": "UgU75eFkU519"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng13QOnlPJk_",
        "outputId": "a34c1d89-5a59-4466-9e3c-d68c389483b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slK41ebrPQY6",
        "outputId": "59af4d6c-59f7-46e4-bfc8-8a2f77607620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Input shape: {X.shape}')\n",
        "print(f'Output shape: {y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjOwinPTVBrj",
        "outputId": "8ec5e932-018a-42e6-ad1e-9ff6ab56dd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (132, 20)\n",
            "Output shape: (132, 82)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_length = X.shape[1]"
      ],
      "metadata": {
        "id": "qRaIMs-MVVg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR762EEmVXOC",
        "outputId": "1e9ba428-4758-4c79-bb26-e0609cd2698c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import  Bidirectional,Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "model = models.Sequential()\n",
        "model.add(Embedding(82,100,input_length=20))\n",
        "model.add(LSTM(64))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(82,activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "btRya4nRVFDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = models.Sequential()\n",
        "model.add(Embedding(82,100,input_length=20))\n",
        "model.add(LSTM(150,return_sequences=True))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(82,activation='softmax'))"
      ],
      "metadata": {
        "id": "oKFJQpMvp-1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(Embedding(82,100,input_length=20))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(82,activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "Nto-dnn9cW9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "h8RK6LYHjMXo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"The course follows\"\n",
        "for i in range(10):\n",
        "  token_text=tokenizer.texts_to_sequences([text])[0]\n",
        "  padden_token_text=pad_sequences([token_text],maxlen=20,padding='pre')\n",
        "  pos=np.argmax(model.predict(padden_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "\n",
        "    if index==pos:\n",
        "      text=text + \" \" + word\n",
        "      print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AACjZO0jpJ1x",
        "outputId": "fbbf3f13-39cd-4942-9341-aacae06ec6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "The course follows a\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "The course follows a monthly\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "The course follows a monthly subscription\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "The course follows a monthly subscription model\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "The course follows a monthly subscription model where\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "The course follows a monthly subscription model where you\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "The course follows a monthly subscription model where you have\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "The course follows a monthly subscription model where you have to\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "The course follows a monthly subscription model where you have to make\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "The course follows a monthly subscription model where you have to make monthly\n"
          ]
        }
      ]
    }
  ]
}